{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8858637,"sourceType":"datasetVersion","datasetId":2857519},{"sourceId":8869873,"sourceType":"datasetVersion","datasetId":5338125}],"dockerImageVersionId":30732,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom skimage import io\nimport cv2\nimport random\nimport os\nimport shutil\n\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2024-07-05T14:19:00.186463Z","iopub.execute_input":"2024-07-05T14:19:00.187296Z","iopub.status.idle":"2024-07-05T14:19:06.714588Z","shell.execute_reply.started":"2024-07-05T14:19:00.187242Z","shell.execute_reply":"2024-07-05T14:19:06.713786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATA_PATH = \"/kaggle/input/cattle-weight-detection-model-dataset-12k/www.acmeai.tech Dataset - BMGF-LivestockWeight-CV\"\nJSON_PATH_REAR = os.path.join(DATA_PATH, \"Vector/B4/Rear/data/coco_b4_rear.json\")\nIMAGE_DIR_REAR = os.path.join(DATA_PATH, \"Vector/B4/Rear/data/images\")\n\nJSON_PATH_SIDE = os.path.join(DATA_PATH, \"Vector/B4/Side/data/coco_b4_side.json\")\nIMAGE_DIR_SIDE = os.path.join(DATA_PATH, \"Vector/B4/Side/data/images\")\n\n# Function to load and display the first image along with its keypoints\ndef visualize_first_image(json_path, image_dir):\n    with open(json_path, 'r') as file:\n        coco_data = json.load(file)\n\n    first_image_filename = coco_data['images'][0]['file_name']\n    first_image_keypoints = coco_data['annotations'][0]['keypoints']\n    keypoint_x_vals = first_image_keypoints[0::3]\n    keypoint_y_vals = first_image_keypoints[1::3]\n\n    image_path = os.path.join(image_dir, first_image_filename)\n    image = Image.open(image_path)\n\n    plt.figure(figsize=(10,10))\n    plt.imshow(image)\n    plt.scatter(keypoint_x_vals, keypoint_y_vals, c='r', marker='x')\n    plt.title(f\"First Image with Keypoints from {json_path.split('/')[-2]}\")\n    plt.show()\n# Visualize for both Rear and Side\nvisualize_first_image(JSON_PATH_REAR, IMAGE_DIR_REAR)\nvisualize_first_image(JSON_PATH_SIDE, IMAGE_DIR_SIDE)","metadata":{"execution":{"iopub.status.busy":"2024-07-05T14:19:06.716104Z","iopub.execute_input":"2024-07-05T14:19:06.716551Z","iopub.status.idle":"2024-07-05T14:19:09.022742Z","shell.execute_reply.started":"2024-07-05T14:19:06.716526Z","shell.execute_reply":"2024-07-05T14:19:09.021788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize_first_image(json_path, image_dir, final_ls,size):\n    with open(json_path, 'r') as file:\n        coco_data = json.load(file)\n    for j in range(size):\n        first_image_filename = coco_data['images'][j]['file_name']\n        first_image_keypoints = coco_data['annotations'][j]['keypoints']\n        keypoint_x_vals = first_image_keypoints[0::3]\n        keypoint_y_vals = first_image_keypoints[1::3]\n\n        image_path = os.path.join(image_dir, first_image_filename)\n    #     image = Image.open(image_path)\n\n    #     plt.figure(figsize=(10,10))\n    #     plt.imshow(image)\n    #     plt.scatter(keypoint_x_vals, keypoint_y_vals, c='r', marker='x')\n    #     plt.title(f\"First Image with Keypoints from {json_path.split('/')[-2]}\")\n    #     plt.show()\n        ls = []\n        for i in range(len(keypoint_x_vals)):\n            ls.append([keypoint_x_vals[i],keypoint_y_vals[i]])\n        ls.append(image_path)\n        final_ls.append(ls)","metadata":{"execution":{"iopub.status.busy":"2024-07-05T14:19:32.659936Z","iopub.execute_input":"2024-07-05T14:19:32.660620Z","iopub.status.idle":"2024-07-05T14:19:32.668061Z","shell.execute_reply.started":"2024-07-05T14:19:32.660588Z","shell.execute_reply":"2024-07-05T14:19:32.667128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_ls = []\nJSON_PATH_REAR = os.path.join(DATA_PATH, \"Vector/B4/Rear/data/coco_b4_rear.json\")\nIMAGE_DIR_REAR = os.path.join(DATA_PATH, \"Vector/B4/Rear/data/images\")\nvisualize_first_image(JSON_PATH_REAR, IMAGE_DIR_REAR,final_ls,size=1900)\nJSON_PATH_REAR = os.path.join(DATA_PATH, \"Vector/B3/Rear/data/COCO_B3_rear.json\")\nIMAGE_DIR_REAR = os.path.join(DATA_PATH, \"Vector/B3/Rear/data/images\")\nvisualize_first_image(JSON_PATH_REAR, IMAGE_DIR_REAR,final_ls,size=2500)","metadata":{"execution":{"iopub.status.busy":"2024-07-05T14:19:33.039749Z","iopub.execute_input":"2024-07-05T14:19:33.040518Z","iopub.status.idle":"2024-07-05T14:19:33.315274Z","shell.execute_reply.started":"2024-07-05T14:19:33.040487Z","shell.execute_reply":"2024-07-05T14:19:33.314485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ncolumns = ['one','two','three','four','image_path']\ndf = pd.DataFrame(final_ls,columns = columns)","metadata":{"execution":{"iopub.status.busy":"2024-07-05T14:19:51.988971Z","iopub.execute_input":"2024-07-05T14:19:51.989602Z","iopub.status.idle":"2024-07-05T14:19:51.998902Z","shell.execute_reply.started":"2024-07-05T14:19:51.989569Z","shell.execute_reply":"2024-07-05T14:19:51.997542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2024-07-05T14:19:55.029527Z","iopub.execute_input":"2024-07-05T14:19:55.030322Z","iopub.status.idle":"2024-07-05T14:19:55.055805Z","shell.execute_reply.started":"2024-07-05T14:19:55.030291Z","shell.execute_reply":"2024-07-05T14:19:55.054849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = df","metadata":{"execution":{"iopub.status.busy":"2024-07-05T14:20:12.794732Z","iopub.execute_input":"2024-07-05T14:20:12.795176Z","iopub.status.idle":"2024-07-05T14:20:12.799422Z","shell.execute_reply.started":"2024-07-05T14:20:12.795145Z","shell.execute_reply":"2024-07-05T14:20:12.798478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nfrom skimage import io\nimport cv2\nplt.figure(figsize = (10,10))\nfor plot_index in range(9):\n    index  = random.randint(0, len(train_dataset) - 1)\n    image  = io.imread(train_dataset['image_path'][index],1)\n    points = train_dataset.loc[index][:-1]\n    points = [np.uint(points[x]) for x in range(len(points))]\n    for point_index in range(len(points)):\n        image = cv2.circle(image, points[point_index] , radius=1, color=1, thickness=-1)\n    plt.subplot(3,3, plot_index + 1)\n    plt.imshow(image)\n    plt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2024-07-05T14:20:13.166349Z","iopub.execute_input":"2024-07-05T14:20:13.166708Z","iopub.status.idle":"2024-07-05T14:20:21.896929Z","shell.execute_reply.started":"2024-07-05T14:20:13.166680Z","shell.execute_reply":"2024-07-05T14:20:21.895990Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.mkdir('data')\nos.mkdir('data/images')\nos.mkdir('data/labels')\nos.mkdir('data/images/train')\nos.mkdir('data/images/val')\nos.mkdir('data/labels/train')\nos.mkdir('data/labels/val')","metadata":{"execution":{"iopub.status.busy":"2024-07-05T14:20:21.898715Z","iopub.execute_input":"2024-07-05T14:20:21.899109Z","iopub.status.idle":"2024-07-05T14:20:21.905299Z","shell.execute_reply.started":"2024-07-05T14:20:21.899079Z","shell.execute_reply":"2024-07-05T14:20:21.904398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# split into train and val\nfor index in range(len(train_dataset) - 200):\n    file_name = os.path.split(train_dataset.loc[index]['image_path'])[1].split('.')[0]\n    inst_data = [0, 0.5,0.5,0.5,0.5]\n    label_path = os.path.join('/kaggle/working/data/labels/train/', (file_name + '.txt'))\n    image_path = os.path.join('/kaggle/working/data/images/train/', (file_name + '.jpg'))\n    binary_image = cv2.imread(train_dataset.loc[index]['image_path'], cv2.IMREAD_GRAYSCALE)\n    H, W = binary_image.shape\n    slc = train_dataset.iloc[index].to_numpy(copy=True)[:-1]\n    for i in range(4):\n        inst_data.extend([slc[i][0]/W, slc[i][1]/H])\n    np.array(inst_data,dtype = object).tofile(f'{label_path}', sep=' ')\n    shutil.copyfile(train_dataset.loc[index]['image_path'], image_path)","metadata":{"execution":{"iopub.status.busy":"2024-07-05T14:20:21.906642Z","iopub.execute_input":"2024-07-05T14:20:21.906961Z","iopub.status.idle":"2024-07-05T14:26:49.142993Z","shell.execute_reply.started":"2024-07-05T14:20:21.906934Z","shell.execute_reply":"2024-07-05T14:26:49.142149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for index in range((len(train_dataset) - 200), len(train_dataset)):\n    file_name = os.path.split(train_dataset.loc[index]['image_path'])[1].split('.')[0]\n    inst_data = [0, 0.5,0.5,0.5,0.5]\n    label_path = os.path.join('/kaggle/working/data/labels/val/', (file_name + '.txt'))\n    image_path = os.path.join('/kaggle/working/data/images/val/', (file_name + '.jpg'))\n    binary_image = cv2.imread(train_dataset.loc[index]['image_path'], cv2.IMREAD_GRAYSCALE)\n    H, W = binary_image.shape\n    slc = train_dataset.iloc[index].to_numpy(copy=True)[:-1]\n    for i in range(4):\n        inst_data.extend([slc[i][0]/W, slc[i][1]/H])\n    np.array(inst_data,dtype = object).tofile(f'{label_path}', sep=' ')\n    shutil.copyfile(train_dataset.loc[index]['image_path'], image_path)","metadata":{"execution":{"iopub.status.busy":"2024-07-05T14:26:49.144888Z","iopub.execute_input":"2024-07-05T14:26:49.145170Z","iopub.status.idle":"2024-07-05T14:27:16.876632Z","shell.execute_reply.started":"2024-07-05T14:26:49.145146Z","shell.execute_reply":"2024-07-05T14:27:16.875622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install ultralytics","metadata":{"execution":{"iopub.status.busy":"2024-07-05T14:27:16.877852Z","iopub.execute_input":"2024-07-05T14:27:16.878204Z","iopub.status.idle":"2024-07-05T14:27:33.282273Z","shell.execute_reply.started":"2024-07-05T14:27:16.878172Z","shell.execute_reply":"2024-07-05T14:27:33.281325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wandb\napi_key = 'ccdf912083f622610063ad0ff31defb3972f6ee7'\nwandb.login(key=api_key,relogin=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-05T14:27:33.283839Z","iopub.execute_input":"2024-07-05T14:27:33.284212Z","iopub.status.idle":"2024-07-05T14:27:38.651181Z","shell.execute_reply.started":"2024-07-05T14:27:33.284173Z","shell.execute_reply":"2024-07-05T14:27:38.650300Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from ultralytics import YOLO\nmodel = YOLO('yolov8l-pose.pt')  # load a pretrained model (recommended for training)\nresults = model.train(data='/kaggle/input/dummy-yaml/data_keypoint_model.yaml',\n                      epochs=50, imgsz=640, cache = True, pretrained = True)","metadata":{"execution":{"iopub.status.busy":"2024-07-05T14:27:38.652884Z","iopub.execute_input":"2024-07-05T14:27:38.653415Z","iopub.status.idle":"2024-07-05T14:37:34.549402Z","shell.execute_reply.started":"2024-07-05T14:27:38.653387Z","shell.execute_reply":"2024-07-05T14:37:34.548418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}